{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[Google Vision python docs](https://googleapis.dev/python/vision/latest/index.html)\n",
    "\n",
    "cf. [another tutorial](https://cloud.google.com/functions/docs/tutorials/ocr), which uses cloud functions\n",
    "\n",
    "It turns out, google OCR will work with PDFs only if thy are stored in google cloud. Since that just adds another layer of complexity, I'm going to work with Backblaze"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "from google.oauth2 import service_account\n",
    "creds_path = '/home/src/oed/creds.json'\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(creds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 42625,\n",
      "  \"iopub_port\": 34709,\n",
      "  \"stdin_port\": 34463,\n",
      "  \"control_port\": 38627,\n",
      "  \"hb_port\": 32969,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"fc881614-4166bf89ba71261b08a7a703\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-af21ada3-6f4e-430b-8015-e238442182df.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "from google.cloud import vision\n",
    "client = vision.ImageAnnotatorClient(credentials=creds)\n",
    "\n",
    "\n",
    "feature = vision.Feature(\n",
    "    type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "# async_request = vision.AsyncAnnotateFileRequest(\n",
    "#     features=[feature], input_config=input_config,\n",
    "#     output_config=output_config)\n",
    "\n",
    "source_uri = 'https://jeroen.github.io/images/testocr.png'\n",
    "# source_uri = 'https://africau.edu/images/default/sample.pdf'\n",
    "\n",
    "source_uri = 'https://ohuiginn.net/tmp/singlepage-1.png'\n",
    "image_src = vision.ImageSource(image_uri = source_uri)\n",
    "img = vision.Image(source=image_src)\n",
    "page_as_protobuf = client.annotate_image({\n",
    "    'image': img,\n",
    "\n",
    "# 'image': {'source': {'image_uri': source_uri}},\n",
    "    'features': [feature]\n",
    "})\n",
    "page_as_protobuf\n",
    "page_as_dict = MessageToDict(page_as_protobuf._pb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# cargo-cult from https://towardsdatascience.com/how-to-extract-the-text-from-pdfs-using-python-and-the-google-cloud-vision-api-7a0a798adc13\n",
    "\n",
    "\n",
    "# Display with bounding boxes\n",
    "# from https://cloud.google.com/vision/docs/fulltext-annotations\n",
    "import argparse\n",
    "from enum import Enum\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    WORD = 4\n",
    "    SYMBOL = 5\n",
    "\n",
    "\n",
    "def draw_boxes(image, bounds, color):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        draw.polygon([\n",
    "            bound.vertices[0].x, bound.vertices[0].y,\n",
    "            bound.vertices[1].x, bound.vertices[1].y,\n",
    "            bound.vertices[2].x, bound.vertices[2].y,\n",
    "            bound.vertices[3].x, bound.vertices[3].y], None, color)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_document_bounds(image_file, feature):\n",
    "    \"\"\"Returns document bounds given an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient(credentials=creds)\n",
    "\n",
    "    bounds = []\n",
    "\n",
    "    with io.open(image_file, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "    document = response.full_text_annotation\n",
    "\n",
    "    # Collect specified feature bounds by enumerating all document features\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        if (feature == FeatureType.SYMBOL):\n",
    "                            bounds.append(symbol.bounding_box)\n",
    "\n",
    "                    if (feature == FeatureType.WORD):\n",
    "                        bounds.append(word.bounding_box)\n",
    "\n",
    "                if (feature == FeatureType.PARA):\n",
    "                    bounds.append(paragraph.bounding_box)\n",
    "\n",
    "            if (feature == FeatureType.BLOCK):\n",
    "                bounds.append(block.bounding_box)\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def render_doc_text(filein, fileout):\n",
    "    image = Image.open(filein)\n",
    "    bounds = get_document_bounds(filein, FeatureType.BLOCK)\n",
    "    draw_boxes(image, bounds, 'blue')\n",
    "    bounds = get_document_bounds(filein, FeatureType.PARA)\n",
    "    draw_boxes(image, bounds, 'red')\n",
    "    bounds = get_document_bounds(filein, FeatureType.WORD)\n",
    "    draw_boxes(image, bounds, 'yellow')\n",
    "\n",
    "    if fileout != 0:\n",
    "        image.save(fileout)\n",
    "    else:\n",
    "        image.show()\n",
    "\n",
    "def display_annotation():\n",
    "    file_in = './data/singlepage-1.png'\n",
    "    file_out = '/tmp/singlepage-1-annotated.png'\n",
    "    render_doc_text(file_in, file_out)\n",
    "\n",
    "display_annotation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "coordinates are (0,0) in top right"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}